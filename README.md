# Digital Edition Draft

This repository hosts the working pipeline that transforms a small corpus of Latin poems into progressively enriched TEI files (entities, topics, validation, and visualizations). It is intentionally script-driven so each processing stage can be run on demand.

---

## English

### Overview
- Latin source files under `data_root/` are turned into TEI through a numbered pipeline (`0_*.py` … `8_*.py`).
- Intermediate TEI stages live under `data_root/tei_pipeline/<step>/`, ending in Relax NG validated outputs (step `08`) and visual aids (step `09`).
- Supporting CSVs (entities, VIAF, Pleiades, Wikidata, topics) live under `data_root/entities/` and `data_root/outputs/`.

### Requirements
- Python 3.10+ (the repo is exercised with `py -3.11` on Windows).
- Install dependencies: `pip install -r requirements.txt`.
- Extra assets (LatinCy model metadata) are stored in `hf_model.json`, `hf_latincy.json`, etc.; the actual model wheel is *not* tracked, so download via `python -m spacy download la_core_web_lg` when you set up the environment.

### Data Layout
```
data_root/
  Catulo_*txt, Tibulo_*txt          # source poems
  entities/                         # CSVs generated by entity scripts
  outputs/                          # topic matching exports
  soldevila/, tei_pipeline/, ...    # intermediate products
```

### Running the Pipeline
1. Ensure `data_root/` contains the plain-text poems and any optional PDFs (Index Nominum, Pleiades CSVs). The repo already ships sample data.
2. Execute scripts in order—they are independent files so you can re-run any step without touching others:
   - `0_tei_header_and_verses.py`: build TEI skeletons and count verses.
   - `1_entities_pipeline.py`: detect/tag entities, export CSV summaries, compare with index PDFs.a
   - `2_viaf_linking.py`, `3_pleiades_linking.py`, `4_wikidata_linking.py`: progressively enrich the entity CSV with external identifiers.
   - `5_topic_matching.py`: run Soldevila topic matching against the poems.
   - `6_tei_topic_annotation.py`: write the topic spans back to TEI (standOff, flatten, combined).
   - `7_tei_relaxng_header_and_validation.py`: refresh TEI headers and validate them with the official Relax NG schema.
   - `8_tei_visualizations.py`: generate topic bar charts/graphs into `data_root/tei_pipeline/09_tei_visualizations/`.
3. Inspect `data_root/tei_pipeline/08_tei_header_with_relaxng/{standoff,flatten,combined}` for the final TEI packages.

### Notes
- Every script logs to stdout; keep PowerShell open to diagnose warnings (e.g., missing PDFs or HTTP throttling when hitting Wikidata).
- The repo avoids storing large proprietary assets. If you add new corpora or indexes, keep them under `data_root/` so they stay out of version control.

---

## Español

### Descripcion general
- Los poemas en `data_root/` se procesan paso a paso con los scripts numerados hasta obtener TEI enriquecidos y validados.
- Cada etapa del pipeline escribe su propia carpeta en `data_root/tei_pipeline/`, lo que permite volver a correr solo el paso que necesites.
- Los CSV con entidades y enlaces externos viven en `data_root/entities/`; los resultados de temas aparecen en `data_root/outputs/`.

### Requisitos
- Python 3.10 o superior (`py -3.11` funciona bien en Windows).
- Instala dependencias con `pip install -r requirements.txt`.
- Descarga el modelo `la_core_web_lg` de spaCy (solo se guardan metadatos en este repo).

### Ejecucion del pipeline
1. Verifica que `data_root/` tenga los textos fuente y los PDFs opcionales.
2. Ejecuta los scripts `0_` a `8_` en orden cuando necesites regenerar resultados (cada script se puede correr de forma aislada).
3. Revisa los TEI finales en `data_root/tei_pipeline/08_tei_header_with_relaxng/`. Los graficos producidos por el paso `8` quedan en `data_root/tei_pipeline/09_tei_visualizations/`.

### Consejos
- Los mensajes `[WARN]` indican archivos ausentes o problemas de red; vuelve a lanzar el script una vez resuelto.
- Para agregar nuevos textos/clasificaciones, sigue la misma estructura de carpetas y evita subir archivos pesados al repositorio publico.

---

## Português

### Visao geral
- Os poemas localizados em `data_root/` passam por scripts numerados que geram TEI enriquecidos com entidades, topicos e validacao.
- Cada fase escreve em `data_root/tei_pipeline/<etapa>/`, facilitando reprocessar somente o trecho necessario.
- Dados auxiliares (CSV de entidades, correspondencias VIAF/Pleiades/Wikidata, matches de topicos) ficam em `data_root/entities/` e `data_root/outputs/`.

### Requisitos
- Python 3.10+.
- `pip install -r requirements.txt` para preparar o ambiente.
- Baixe o modelo spaCy `la_core_web_lg` localmente (apenas os metadados estao versionados aqui).

### Como executar
1. Garanta que os textos e PDFs estejam em `data_root/`.
2. Rode cada script numerado do `0_` ao `8_` conforme necessario; cada um pode ser reexecutado sem refazer o restante.
3. Os TEI finais (validados) ficam em `data_root/tei_pipeline/08_tei_header_with_relaxng/`; as visualizacoes criadas no passo `8` vao para `data_root/tei_pipeline/09_tei_visualizations/`.

### Dicas
- Monitore a saida no terminal para checar alertas sobre dados faltando ou limites de API.
- Mantenha os assets grandes fora do controle de versao e documente os passos de download quando compartilhar o projeto.
